### bindOI: Concept Operating Interface For the Visually Impaired
</br>
</br>

#### Code & Files
- [Code folder](https://drive.google.com/drive/folders/1yUbV3VjX3Jasnvd_OFGMxiV0u8tXPYp6?usp=sharing)
- [Data foler](https://drive.google.com/drive/folders/1dTroHtgS9cep5CFhvXOFp-z-8uQaxCka?usp=sharing)
- [Model folder](https://drive.google.com/drive/folders/1iO76YteRA0e2U6wuBDHDtrucM66aWJhu?usp=sharing)
</br>

#### Motivation
Computers that require operation through direct touch with the devices create an extra layer of inconvenience for the visually impaired. Developing a concept for a more user-friendly Operation Interface (OI) leverging existing computer vision technologies without the need for direct mannual controls yeilds a better use case for these population. Such an OI may also be extended to more advanced use cases as the world moves into the era of VR/AR. 
</br>
</br>

#### Version History
- Version 1: Minimum working pipeline (utilities, data collection, modeling, training, evaluation, and live demo) with demonstrable but suboptimal performance
</br>

#### Future Versions
- Version 2: Collect more variations of training data to incorporate more shapes & sizes of bodies and hands to improve action recognition accuracy
- Version 3: Further refine training data and model to improve action recognition _efficiency_ (i.e. how long it takes to make an accurate prediction)
</br>

#### Algorithm
- Long/Short-Term Memory (LSTM)
